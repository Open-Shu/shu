"""Pydantic schemas for document and chunk profiling (SHU-343).

These schemas define the structure of profile data generated by ProfilingService
and stored in Document and DocumentChunk records.
"""

from enum import Enum

from pydantic import BaseModel, Field


class DocumentType(str, Enum):
    """Classification of document type for retrieval optimization."""

    NARRATIVE = "narrative"  # Stories, reports, articles
    TRANSACTIONAL = "transactional"  # Emails, invoices, receipts
    TECHNICAL = "technical"  # Manuals, specs, code docs
    CONVERSATIONAL = "conversational"  # Chat logs, meeting notes


class ProfilingStatus(str, Enum):
    """Status of document profiling process."""

    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETE = "complete"
    FAILED = "failed"


class ProfilingMode(str, Enum):
    """How the document was profiled."""

    FULL_DOCUMENT = "full_document"  # Entire doc sent to LLM
    CHUNK_AGGREGATION = "chunk_aggregation"  # Aggregated from chunk profiles


class CapabilityManifest(BaseModel):
    """Structured declaration of what a document can answer.

    Used for capability-aware retrieval filtering. The answers_questions_about
    field should contain SPECIFIC, DISTINGUISHING details - not generic categories.
    """

    answers_questions_about: list[str] = Field(
        default_factory=list,
        description="SPECIFIC topics with named entities, dates, figures. "
        "E.g., 'Acme Corp Q3 2024 revenue', not 'financial performance'",
    )
    provides_information_type: list[str] = Field(
        default_factory=list,
        description="Type of information: facts, opinions, decisions, instructions, etc.",
    )
    authority_level: str = Field(
        default="secondary",
        description="primary (authoritative source), secondary (derived), commentary",
    )
    completeness: str = Field(
        default="partial",
        description="complete (standalone), partial (needs context), reference",
    )
    question_domains: list[str] = Field(
        default_factory=list,
        description="Types of questions: who, what, when, where, why, how",
    )


class ChunkProfile(BaseModel):
    """Profile data for a single document chunk.

    Used for retrieval-time filtering and LLM-scannable indexing.
    """

    summary: str = Field(
        ...,
        description="One-line summary with SPECIFIC content (names, figures, dates). "
        "Used for agent scanning and synopsis accumulation.",
    )
    keywords: list[str] = Field(
        default_factory=list,
        description="Specific extractable terms: names, numbers, dates, technical terms",
    )
    topics: list[str] = Field(
        default_factory=list,
        description="Conceptual categories the chunk relates to",
    )


class DocumentProfile(BaseModel):
    """Complete profile for a document.

    Generated by ProfilingService via incremental chunk profiling.
    """

    synopsis: str = Field(
        ...,
        description="One-paragraph summary capturing document essence",
    )
    document_type: DocumentType = Field(
        ...,
        description="Classification for retrieval optimization",
    )
    capability_manifest: CapabilityManifest = Field(
        default_factory=CapabilityManifest,
        description="What questions/queries this document can satisfy",
    )


class ChunkData(BaseModel):
    """Input data for chunk profiling."""

    chunk_id: str = Field(..., description="Unique identifier for the chunk")
    chunk_index: int = Field(..., description="Position within the document")
    content: str = Field(..., description="Chunk text content")


class ChunkProfileResult(BaseModel):
    """Result of profiling a single chunk, including its ID."""

    chunk_id: str = Field(..., description="ID of the profiled chunk")
    chunk_index: int = Field(..., description="Position within the document")
    profile: ChunkProfile = Field(..., description="Generated profile data")
    success: bool = Field(True, description="Whether profiling succeeded")
    error: str | None = Field(None, description="Error message if failed")


class ProfilingResult(BaseModel):
    """Complete result of profiling a document and its chunks."""

    document_id: str = Field(..., description="ID of the profiled document")
    document_profile: DocumentProfile | None = Field(None, description="Document-level profile (may be None if failed)")
    chunk_profiles: list[ChunkProfileResult] = Field(default_factory=list, description="Profiles for each chunk")
    profiling_mode: ProfilingMode = Field(..., description="How the document was profiled (always CHUNK_AGGREGATION)")
    success: bool = Field(True, description="Overall success status")
    error: str | None = Field(None, description="Error message if failed")
    tokens_used: int = Field(0, description="Total tokens used for profiling")
    duration_ms: int = Field(0, description="Total profiling duration in milliseconds")


class UnifiedChunkProfile(BaseModel):
    """Chunk profile from final batch LLM response.

    Includes chunk index for mapping back to chunks.
    """

    index: int = Field(..., description="Chunk index within the document")
    summary: str = Field(
        ...,
        description="One-line summary with SPECIFIC content (names, figures, dates). "
        "Used for agent scanning and synopsis accumulation.",
    )
    keywords: list[str] = Field(default_factory=list, description="Specific extractable terms")
    topics: list[str] = Field(default_factory=list, description="Conceptual categories")


class FinalBatchResponse(BaseModel):
    """Response from final batch profiling for large documents.

    The final batch produces both chunk profiles AND document-level metadata,
    eliminating the need for a separate aggregation LLM call.
    """

    chunks: list[UnifiedChunkProfile] = Field(default_factory=list, description="Per-chunk profiles for this batch")
    synopsis: str = Field(..., description="2-4 sentence document summary derived from accumulated summaries")
    document_type: str = Field(..., description="narrative, transactional, technical, conversational")
    capability_manifest: CapabilityManifest = Field(
        default_factory=CapabilityManifest,
        description="What questions this document can answer",
    )
    synthesized_queries: list[str] = Field(
        default_factory=list,
        description="Hypothetical queries this document can satisfy",
    )
